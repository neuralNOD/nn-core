{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align = \"center\">Univariate LSTM Network</h1>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "**Objective:** Create a *bare neural network* LSTM model for univariate time series data and check the functionalities and capabilities. Note the model developed here are just for informational purpose and the actual model is to be developed and trained in cloud. The notebook also serves as a reference to all the *beautiful* custom-built user-defined functionalities available.\n",
    "\n",
    "## Prediction of Future Sequence\n",
    "\n",
    "A LSTM network can be developed to predict future sequence of a given length (defined as **`n_forecast`**) by - (I) creating a output layer (generally `Dense`) of `length == n_forecast`, as described [here](https://stackoverflow.com/a/69912334/6623589), or (II) create a function that takes previous input and keep on iterating for `n_forecast` as in [this video](https://youtu.be/UbvkhuqVqUI?t=1026). In this notebook, both the approach is tried however the accuracy metric and performance comparison are to be added later. The `n_lookup` and `n_forecast` can be explained as in:\n",
    "\n",
    "![prediction-sequence](https://i.stack.imgur.com/YXwMJ.png)\n",
    "\n",
    "where, $T$ is the lookback period defined as **`n_lookup`** throught the code, and $H$ is the forecast period defined as **`n_forecast`**.\n",
    "\n",
    "### Lookback Period (`n_lookup`)\n",
    "\n",
    "The day's considered while model training. Based on *previous analysis* it is observed that past fifteen (15) days data has an impact on the bid execution day (i.e. $D_{t_{1}}$) thus for model training we can cosider a sequence of shape `(-1, 15 * 96, 1)` where `96` is the number of blocks for a day. Thus, `n_lookup` will take a sequence data comprising of $D_{t_{-16}}$ to $D_{t_{-2}}$ while sitting on $D_{t_{-1}}$ to predict.\n",
    "\n",
    "### Forecast Period (`n_forecast`)\n",
    "\n",
    "Sitting on $D_{t_{-1}}$ to predict, the bids are to be placed on $D_{t_{0}}$ for $D_{t_{1}}$ thus we need `2 * 96 = 192` worth sequence of data. While some data may already available, this needs more clarifications and thus total data of $D_{t_{0}}$ is neglected for all markets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T07:55:03.188802Z",
     "start_time": "2023-02-21T07:55:03.173355Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Code Version: #ideation v0.0.1-alpha (#semver v2.0.0)\n"
     ]
    }
   ],
   "source": [
    "# use the code release version for tracking and code modifications. use the\n",
    "# CHANGELOG.md file to keep track of version features, and/or release notes.\n",
    "# the version file is avaiable at project root directory, check the\n",
    "# global configuration setting for root directory information.\n",
    "# the file is already read and is available as `__version__`\n",
    "__version__ = open(\"../VERSION\", \"rt\").read() # bump codecov\n",
    "print(f\"Current Code Version: {__version__}\") # TODO : author, contact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Imports\n",
    "\n",
    "A code must be written such that it is always _production ready_. The conventional guidelines provided under [**PEP8**](https://peps.python.org/pep-0008/#imports) defines the conventional or syntactically useful ways of defining and/or manipulating functions. Necessar guidelines w.r.t. code imports are mentioned below, and basic libraries and import settings are defined.\n",
    "\n",
    " 1. Imports should be on separate lines,\n",
    " 2. Import order should be:\n",
    "    * standard library/modules,\n",
    "    * related third party imports,\n",
    "    * local application/user defined imports\n",
    " 3. Wildcard import (`*`) should be avoided, else specifically tagged with **`# noqa: F403`** as per `flake8` or **`# pylint: disable=unused-import`** as per `pylint`\n",
    " 4. Avoid using relative imports; use explicit imports instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T07:55:09.930616Z",
     "start_time": "2023-02-21T07:55:09.921620Z"
    }
   },
   "outputs": [],
   "source": [
    "import os   # miscellaneous os interfaces\n",
    "import sys  # configuring python runtime environment\n",
    "import time # library for time manipulation, and logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T07:55:10.180343Z",
     "start_time": "2023-02-21T07:55:10.175343Z"
    }
   },
   "outputs": [],
   "source": [
    "# use `datetime` to control and preceive the environment\n",
    "# in addition `pandas` also provides date time functionalities\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T07:55:10.583507Z",
     "start_time": "2023-02-21T07:55:10.576509Z"
    }
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy      # dataframe is mutable\n",
    "# from tqdm import tqdm as TQ    # progress bar for loops\n",
    "# from uuid import uuid4 as UUID # unique identifier for objs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis and AI/ML Libraries\n",
    "\n",
    "Import of data analysis and AI/ML libraries required at different intersections. Check settings and configurations [here](https://gitlab.com/ZenithClown/computer-configurations-and-setups) and code snippets [here](https://gitlab.com/ZenithClown/computer-configurations-and-setups/-/tree/master/template/snippets/vscode) for understanding settings that is used in this notebook. The code uses `matplotlib.styles` which is a custom `.mplstyle` file recognised by the `matplotlib` downlodable from [this link](https://gitlab.com/ZenithClown/computer-configurations-and-setups/-/tree/master/settings/python/matplotlib)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T07:55:13.353224Z",
     "start_time": "2023-02-21T07:55:11.936644Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%precision 3\n",
    "%matplotlib inline\n",
    "sns.set_style('whitegrid');\n",
    "plt.style.use('default-style');\n",
    "\n",
    "pd.set_option('display.max_rows', 50) # max. rows to show\n",
    "pd.set_option('display.max_columns', 15) # max. cols to show\n",
    "np.set_printoptions(precision = 3, threshold = 15) # set np options\n",
    "pd.options.display.float_format = '{:,.3f}'.format # float precisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T07:55:14.423356Z",
     "start_time": "2023-02-21T07:55:14.264621Z"
    }
   },
   "outputs": [],
   "source": [
    "# for rmse, use `squared = False` : https://stackoverflow.com/a/18623635/\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error as MSE,\n",
    "    mean_absolute_error as MAE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T07:55:19.292834Z",
     "start_time": "2023-02-21T07:55:15.520396Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Version: 2.9.0\n",
      "\n",
      "GPU Computing Available. EXPERIMENTAL : {'device_name': 'NVIDIA GeForce GTX 1650', 'compute_capability': (7, 5)}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(f\"Tensorflow Version: {tf.__version__}\", end = \"\\n\\n\") # required >= 2.8\n",
    "\n",
    "# check physical devices, and gpu compute capability (if available)\n",
    "if len(tf.config.list_physical_devices(device_type = \"GPU\")):\n",
    "    # https://stackoverflow.com/q/38009682/6623589\n",
    "    # https://stackoverflow.com/a/59179238/6623589\n",
    "    print(\"GPU Computing Available.\", end = \" \")\n",
    "    \n",
    "    # experimentally, get the gpu details and computation power\n",
    "    # https://www.tensorflow.org/api_docs/python/tf/config/experimental/get_device_details\n",
    "    devices = tf.config.list_physical_devices(device_type = \"GPU\")[0] # first\n",
    "    details = tf.config.experimental.get_device_details(devices) # only first\n",
    "    details.get('device_name', 'compute_capability')\n",
    "    print(f\"EXPERIMENTAL : {details}\")\n",
    "else:\n",
    "    print(\"GPU Computing Not Available. If `GPU` is present, check configuration. Detected Devices:\")\n",
    "    print(\"  > \", tf.config.list_physical_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Defined Function(s)\n",
    "\n",
    "It is recommended that any UDFs are defined outside the scope of the *jupyter notebook* such that development/editing of function can be done more practically. As per *programming guidelines* as [`src`](https://fileinfo.com/extension/src) file/directory is beneficial in code development and/or production release. However, *jupyter notebook* requires *kernel restart* if any imported code file is changed in disc, for this frequently changing functions can be defined in this section.\n",
    "\n",
    "**Getting Started** with **`PYTHONPATH`**\n",
    "\n",
    "One must know what are [Environment Variable](https://medium.com/chingu/an-introduction-to-environment-variables-and-how-to-use-them-f602f66d15fa) and how to call/use them in your choice of programming language. Note that an environment variable is *case sensitive* in all operating systems (except windows, since DOS is not case sensitive). Generally, we can access environment variables from terminal/shell/command prompt as:\n",
    "\n",
    "```shell\n",
    "# macOS/*nix\n",
    "echo $VARNAME\n",
    "\n",
    "# windows\n",
    "echo %VARNAME%\n",
    "```\n",
    "\n",
    "Once you've setup your system with [`PYTHONPATH`](https://bic-berkeley.github.io/psych-214-fall-2016/using_pythonpath.html) as per [*python documentation*](https://docs.python.org/3/using/cmdline.html#envvar-PYTHONPATH) is an important directory where any `import` statements looks for based on their order of importance. If a source code/module is not available check necessary environment variables and/or ask the administrator for the source files. For testing purpose, the module boasts the use of `src`, `utils` and `config` directories. However, these directories are available at `ROOT` level, and thus using `sys.path.append()` to add directories while importing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T07:55:22.944558Z",
     "start_time": "2023-02-21T07:55:22.929560Z"
    }
   },
   "outputs": [],
   "source": [
    "# append `src` and sub-modules to call additional files these directory are\n",
    "# project specific and not to be added under environment or $PATH variable\n",
    "sys.path.append(os.path.join(\"..\", \"src\")) # parent/source files directory\n",
    "sys.path.append(os.path.join(\"..\", \"src\", \"agents\")) # agents for reinforcement modelling\n",
    "sys.path.append(os.path.join(\"..\", \"src\", \"engine\")) # derivative engines for model control\n",
    "sys.path.append(os.path.join(\"..\", \"src\", \"models\")) # actual models for decision making tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T07:55:25.678221Z",
     "start_time": "2023-02-21T07:55:25.673230Z"
    }
   },
   "outputs": [],
   "source": [
    "# also append the `utilities` directory for additional helpful codes\n",
    "sys.path.append(os.path.join(\"..\", \"utilities\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T07:55:27.733366Z",
     "start_time": "2023-02-21T07:55:27.704062Z"
    }
   },
   "outputs": [],
   "source": [
    "from plotting import * # noqd: F403 # pylint: disable=unused-import\n",
    "\n",
    "from trainer import base\n",
    "from lstm import BareLSTM\n",
    "from featuring import CreateSequence\n",
    "from scaler import UnivariateRangedScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Argument(s)\n",
    "\n",
    "The global arguments are *notebook* specific, however they may also be extended to external libraries and functions on import. The *boilerplate* provides a basic ML directory structure which contains a directory for `data` and a separate directory for `output`. In addition, a separate directory (`data/processed`) is created to save processed dataset such that preprocessing can be avoided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T07:55:44.329170Z",
     "start_time": "2023-02-21T07:55:44.314177Z"
    }
   },
   "outputs": [],
   "source": [
    "ROOT = \"..\" # the document root is one level up, that contains all code structure\n",
    "DATA = os.path.join(ROOT, \"data\") # the directory contains all data files, subdirectory (if any) can also be used/defined\n",
    "\n",
    "# processed data directory can be used, such that preprocessing steps is not\n",
    "# required to run again-and-again each time on kernel restart\n",
    "PROCESSED_DATA = os.path.join(DATA, \"processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T07:55:46.586901Z",
     "start_time": "2023-02-21T07:55:46.577901Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code Execution Started on: Tue, Feb 21 2023\n"
     ]
    }
   ],
   "source": [
    "# long projects can be overwhelming, and keeping track of files, outputs and\n",
    "# saved models can be intriguing! to help this out, `today` can be used. for\n",
    "# instance output can be stored at `output/<today>/` etc.\n",
    "# `today` is so configured that it permits windows/*.nix file/directory names\n",
    "today = dt.datetime.strftime(dt.datetime.strptime(time.ctime(), \"%a %b %d %H:%M:%S %Y\"), \"%a, %b %d %Y\")\n",
    "print(f\"Code Execution Started on: {today}\") # only date, name of the sub-directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T07:55:49.372529Z",
     "start_time": "2023-02-21T07:55:49.366515Z"
    }
   },
   "outputs": [],
   "source": [
    "OUTPUT_DIR = os.path.join(ROOT, \"output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Input File(s)\n",
    "\n",
    "A typical machine learning project revolves around six important stages (as available in [Amazon ML Life Cycle Documentation](https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/well-architected-machine-learning-lifecycle.html)). The notebook boilerplate is provided to address two pillars:\n",
    "\n",
    " 1. **Data Processing:** An integral part of any machine learning project, which is the most time consuming step! A brief introduction and best practices is available [here](https://towardsdatascience.com/introduction-to-data-preprocessing-in-machine-learning-a9fa83a5dc9d).\n",
    " 2. **Model Development:** From understanding to deployment, this section address development (training, validating and testing) of an machine learning model.\n",
    "\n",
    "![ML Life Cycle](https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/images/ml-lifecycle.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T07:55:51.753968Z",
     "start_time": "2023-02-21T07:55:51.710987Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EffectiveDate</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>BlockID</th>\n",
       "      <th>PurchaseBid</th>\n",
       "      <th>SellBid</th>\n",
       "      <th>MCV</th>\n",
       "      <th>MCP</th>\n",
       "      <th>scaled(MCP)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>237762</th>\n",
       "      <td>2019-01-12</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>67</td>\n",
       "      <td>9,842.600</td>\n",
       "      <td>7,811.800</td>\n",
       "      <td>6,198.970</td>\n",
       "      <td>4,200.670</td>\n",
       "      <td>1.206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       EffectiveDate  year  month  day  BlockID  PurchaseBid   SellBid  \\\n",
       "237762    2019-01-12  2019      1   12       67    9,842.600 7,811.800   \n",
       "\n",
       "             MCV       MCP  scaled(MCP)  \n",
       "237762 6,198.970 4,200.670        1.206  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "market_snapshot = pd.read_pickle(os.path.join(PROCESSED_DATA, \"df_consolidated_2012-04-01_2022-12-31.pickle\"))\n",
    "market_snapshot.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data Arguments\n",
    "\n",
    "Training `data` is read directly from *preprocessed* files (check internal code notebooks for more information) and certain arguments are defined which are required later by the model or during testing/validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T07:55:55.289601Z",
     "start_time": "2023-02-21T07:55:55.272591Z"
    }
   },
   "outputs": [],
   "source": [
    "START_DATE = dt.datetime(year = 2019, month = 4, day = 1)\n",
    "FINAL_DATE = dt.datetime(year = 2022, month = 10, day = 31)\n",
    "# data = market_snapshot[(market_snapshot[\"EffectiveDate\"] >= START_DATE) & (market_snapshot[\"EffectiveDate\"] <= FINAL_DATE)][\"scaled(MCP)\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Formatting for ML Model\n",
    "\n",
    "Load reshaped data for training. Check internal code for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T07:56:27.905237Z",
     "start_time": "2023-02-21T07:56:27.886939Z"
    }
   },
   "outputs": [],
   "source": [
    "n_lookback = 3 * 96 # 🧪 look into 7 days past records\n",
    "n_forecast = 2 * 96 # on t(-1) we want prediction for t(+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-21T07:56:28.922921Z",
     "start_time": "2023-02-21T07:56:28.760800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Data Format: ((125377, 288, 1), (125377, 192, 1))\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(PROCESSED_DATA, \"xy_train_consolidated_2019-04-01_2022-10-31_n_lookback_288_n_forecast_192.npy\"), \"rb\") as fileObj:\n",
    "    x_train = np.load(fileObj)\n",
    "    y_train = np.load(fileObj)\n",
    "\n",
    "print(f\"Processed Data Format: {x_train.shape, y_train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Development\n",
    "\n",
    "The model is developed and trained using *user-defined* functions available typically under **`src`**, which makes it easier to keep all the codes and functionalities same, and just change the model and input to suit the need and easily switch between R&D, testing and production environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T06:11:27.211112Z",
     "start_time": "2023-02-16T06:11:27.204105Z"
    }
   },
   "outputs": [],
   "source": [
    "# neural network parameters, parametric as much possible\n",
    "ACTIVATION_FUNCTION = \"relu\"\n",
    "\n",
    "# model tuning parameters\n",
    "LR_START = 1e-3\n",
    "LR_FINAL = 2e-4\n",
    "NUM_EPOCHS = 3 # keeping small during r&d\n",
    "BATCH_SIZE = 1024\n",
    "\n",
    "# callback and model monitoring criteria\n",
    "LR_FUNC = tf.keras.callbacks.ReduceLROnPlateau(monitor = \"val_loss\", factor = 0.2, patience = 5, min_lr = LR_FINAL)\n",
    "ES_FUNC = tf.keras.callbacks.EarlyStopping(monitor = \"val_loss\", patience = 12, min_delta = 0.001, restore_best_weights = True)\n",
    "TM_FUNC = tf.keras.callbacks.TerminateOnNaN()\n",
    "\n",
    "# define the callbacks for model\n",
    "callbacks = [\n",
    "    LR_FUNC, # learning rate\n",
    "    ES_FUNC, # early stopping of model training\n",
    "    TM_FUNC  # terminate model training on null value\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T06:11:29.788992Z",
     "start_time": "2023-02-16T06:11:29.619485Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://ai.stackexchange.com/a/3162\n",
    "# https://stackoverflow.com/a/59073430\n",
    "# https://stackoverflow.com/a/58868383\n",
    "# https://datascience.stackexchange.com/a/65079\n",
    "# https://datascience.stackexchange.com/a/18049\n",
    "# https://datascience.stackexchange.com/q/12964\n",
    "# conf. paper (word cloud proj.) https://ieeexplore.ieee.org/document/9132839\n",
    "# tensorflow layer not using cuDNN https://stackoverflow.com/q/68844792/6623589\n",
    "\n",
    "model = BareLSTM(\n",
    "    input_shape = (n_lookback, 1), # ⚠ for univariate shape is always `(-1, 1)`\n",
    "    output_shape = n_forecast, # 💿 high network will throw resource error\n",
    "    activation = ACTIVATION_FUNCTION\n",
    ").get_2_layer_lstm(units = [64, 32])\n",
    "model.summary(line_length = 127)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T06:36:51.819774Z",
     "start_time": "2023-02-16T06:11:31.091783Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer = base(model)\n",
    "trainer.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate = LR_START, amsgrad = True),\n",
    "    loss = tf.keras.losses.MeanSquaredError(name = \"loss\"),\n",
    "    metrics = [tf.keras.metrics.RootMeanSquaredError(name = \"RMSE\"), tf.keras.metrics.MeanAbsoluteError(name = \"MAE\")]\n",
    ")\n",
    "\n",
    "# get the history from `.train` method\n",
    "history = trainer.train(x = x_train, y = y_train, num_epochs = NUM_EPOCHS, batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-21T16:01:33.480484Z",
     "start_time": "2023-01-21T16:01:33.411007Z"
    }
   },
   "outputs": [],
   "source": [
    "# model.save(os.path.join(OUTPUT_DIR, \"savedmodels\", f\"{str(dt.datetime.today().date())} {model.name}.h5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation\n",
    "\n",
    "In the below section, we evaluate the model performance based on various factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-17T05:07:44.255165Z",
     "start_time": "2023-02-17T05:07:42.315811Z"
    }
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(os.path.join(OUTPUT_DIR, \"savedmodels\", \"2023-01-21 BareLSTM-1.0.0.h5\"))\n",
    "inverse_scaler = UnivariateRangedScaler(x_min = 0.10 * 1e3, x_max = 12.00 * 1e3, feature_range = (1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T07:16:27.852127Z",
     "start_time": "2023-02-16T07:16:27.189064Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (27, 3))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(history.history[\"loss\"], label = \"loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label = \"val_loss\")\n",
    "\n",
    "plt.title(\"Loss Metric (AUC)\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(history.history[\"MAE\"], label = \"MAE\")\n",
    "plt.plot(history.history[\"val_MAE\"], label = \"val_MAE\")\n",
    "\n",
    "plt.title(\"Mean Absolute Error (MAE)\")\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, \"images\", f\"{str(dt.datetime.today().date())} {model.name}.png\"))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Known Data Block(s)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-17T05:10:19.169961Z",
     "start_time": "2023-02-17T05:10:19.155908Z"
    }
   },
   "outputs": [],
   "source": [
    "TEST_START_DAY = dt.datetime(year = 2022, month = 9, day = 24)\n",
    "TEST_FINAL_DAY = dt.datetime(year = 2022, month = 9, day = 26)\n",
    "\n",
    "PREDICTION_START_DAY = dt.datetime(year = 2022, month = 9, day = 27)\n",
    "PREDICTION_FINAL_DAY = dt.datetime(year = 2022, month = 9, day = 28)\n",
    "\n",
    "test_data = market_snapshot[(market_snapshot[\"EffectiveDate\"] >= TEST_START_DAY) & (market_snapshot[\"EffectiveDate\"] <= TEST_FINAL_DAY)][\"scaled(MCP)\"].values\n",
    "y_actual_ = market_snapshot[(market_snapshot[\"EffectiveDate\"] >= PREDICTION_START_DAY) & (market_snapshot[\"EffectiveDate\"] <= PREDICTION_FINAL_DAY)][\"scaled(MCP)\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-17T05:10:50.916513Z",
     "start_time": "2023-02-17T05:10:48.516112Z"
    }
   },
   "outputs": [],
   "source": [
    "y_predicted = model.predict(test_data.reshape(-1, n_lookback, 1))[0]\n",
    "\n",
    "# calculate the mae and rmse loss for the model as:\n",
    "print(f\"\"\"\n",
    "Error Analysis Report\n",
    "=====================\n",
    "  Mean Absolute Error (MAE)      : {MAE(y_actual_, y_predicted):.5f}\n",
    "  Root Mean Squared Error (RMSE) : {MSE(y_actual_, y_predicted, squared = False):.5f}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-17T05:21:15.131274Z",
     "start_time": "2023-02-17T05:21:14.997280Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (27, 3))\n",
    "\n",
    "plt.plot(y_actual_, label = \"$y$\")\n",
    "plt.plot(y_predicted, label = \"$\\hat{y}$\")\n",
    "\n",
    "plt.xticks([]) # close for now\n",
    "plt.title(f\"Known Data Prediction: Date Span - {TEST_START_DAY.date()} to {PREDICTION_FINAL_DAY.date()}\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unknown Data Block(s)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-17T05:21:56.312150Z",
     "start_time": "2023-02-17T05:21:56.291082Z"
    }
   },
   "outputs": [],
   "source": [
    "TEST_START_DAY = dt.datetime(year = 2022, month = 11, day = 5)\n",
    "TEST_FINAL_DAY = dt.datetime(year = 2022, month = 11, day = 7)\n",
    "\n",
    "PREDICTION_START_DAY = dt.datetime(year = 2022, month = 11, day = 8)\n",
    "PREDICTION_FINAL_DAY = dt.datetime(year = 2022, month = 11, day = 9)\n",
    "\n",
    "test_data = market_snapshot[(market_snapshot[\"EffectiveDate\"] >= TEST_START_DAY) & (market_snapshot[\"EffectiveDate\"] <= TEST_FINAL_DAY)][\"scaled(MCP)\"].values\n",
    "y_actual_ = market_snapshot[(market_snapshot[\"EffectiveDate\"] >= PREDICTION_START_DAY) & (market_snapshot[\"EffectiveDate\"] <= PREDICTION_FINAL_DAY)][\"scaled(MCP)\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-17T05:22:08.659833Z",
     "start_time": "2023-02-17T05:22:07.980843Z"
    }
   },
   "outputs": [],
   "source": [
    "y_predicted = model.predict(test_data.reshape(-1, n_lookback, 1))[0]\n",
    "\n",
    "# calculate the mae and rmse loss for the model as:\n",
    "print(f\"\"\"\n",
    "Error Analysis Report\n",
    "=====================\n",
    "  Mean Absolute Error (MAE)      : {MAE(y_actual_, y_predicted):.5f}\n",
    "  Root Mean Squared Error (RMSE) : {MSE(y_actual_, y_predicted, squared = False):.5f}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-17T05:22:11.973254Z",
     "start_time": "2023-02-17T05:22:11.860040Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (27, 3))\n",
    "\n",
    "plt.plot(y_actual_, label = \"$y$\")\n",
    "plt.plot(y_predicted, label = \"$\\hat{y}$\")\n",
    "\n",
    "plt.xticks([]) # close for now\n",
    "plt.title(f\"Known Data Prediction: Date Span - {TEST_START_DAY.date()} to {PREDICTION_FINAL_DAY.date()}\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "TensorFlow 2.9.0 (GPU)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
